{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:78px\">Final Project IRWA (2024-2025)</p>\n",
    "\n",
    "# Part 3: Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Loading and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local application imports\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in locals() else os.getcwd()\n",
    "project_root = os.path.join(current_dir, '..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import irwa.loading as ild \n",
    "import irwa.preprocessing as ipp\n",
    "import irwa.indexing as ind\n",
    "import irwa.ranking as irk\n",
    "import irwa.evaluation as eva\n",
    "import irwa.saving as sa\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# The following lines allow for autoreload of modules. They allow changes in modules without the need to reload the kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "file_path = '../data/farmers-protest-tweets.json'\n",
    "tweets = ild.load_tweets_from_json(file_path)\n",
    "print(f\"Loaded {len(tweets)} tweets\")\n",
    "\n",
    "# Preprocessing\n",
    "tweet_document_ids_map_df = \"../data/tweet_document_ids_map.csv\"\n",
    "docid_to_tweetid, token_tweets = ipp.create_tokenized_dictionary(tweets, tweet_document_ids_map_df)\n",
    "print(f\"Loaded {len(token_tweets)} documents with their corresponding tokenized tweet content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"What is the indian protest?\"          \n",
    "query2 = \"Where to support the farmers?\"        \n",
    "query3 = \"Who are the Delhi farmers?\"          \n",
    "query4 = \"Is the government corrupt?\"       \n",
    "query5 = \"What do farmers fight for?\"\n",
    "queries = [query1, query2, query3, query4, query5]               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Tf-idf with cosine similarity, custom score and BM25 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inverted index\n",
    "inverted_index, tf, idf = ind.create_inverted_index_tf_idf(token_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking results with TF-IDF\n",
    "ranked_documents_tf_idf = irk.rank_documents_tf_idf(ipp.build_terms(query1), token_tweets, inverted_index, tf, idf, document_filtering=irk.conjunctive_filtering)\n",
    "irk.display_scores_tf_idf(ranked_documents_tf_idf, docid_to_tweetid, tweets, 20)\n",
    "\n",
    "sa.save_scores_to_csv(ranked_documents_tf_idf, filename=\"../data/tf_idf_ranking.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Our score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_documents_our_score_15 = irk.rank_documents_our_score(tweets, docid_to_tweetid, ranked_documents_tf_idf, alpha=0.15, k0 = 0.5, k1=0.5,k2=1,k3=0.5)\n",
    "irk.display_scores_tf_idf(ranked_documents_our_score_15, docid_to_tweetid, tweets, 20)\n",
    "\n",
    "sa.save_scores_to_csv(ranked_documents_our_score_15, filename=\"../data/our_score15_ranking.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_documents_our_score_70 = irk.rank_documents_our_score(tweets, docid_to_tweetid, ranked_documents_tf_idf, alpha=0.7, k0 = 0.5, k1=0.5,k2=1,k3=0.5)\n",
    "irk.display_scores_tf_idf(ranked_documents_our_score_70, docid_to_tweetid, tweets, 20)\n",
    "\n",
    "sa.save_scores_to_csv(ranked_documents_our_score_70, filename=\"../data/our_score70_ranking.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking results with TF-IDF\n",
    "ranked_documents_bm25_b7 = irk.rank_documents_bm25(ipp.build_terms(query1), token_tweets, inverted_index, tf, idf)\n",
    "irk.display_scores_tf_idf(ranked_documents_bm25_b7, docid_to_tweetid, tweets, 20)\n",
    "\n",
    "sa.save_scores_to_csv(ranked_documents_bm25_b7, filename=\"../data/bm25_ranking_b7.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking results with TF-IDF\n",
    "ranked_documents_bm25_b15 = irk.rank_documents_bm25(ipp.build_terms(query1), token_tweets, inverted_index, tf, idf, b= 0.15)\n",
    "irk.display_scores_tf_idf(ranked_documents_bm25_b15, docid_to_tweetid, tweets, 20)\n",
    "\n",
    "sa.save_scores_to_csv(ranked_documents_bm25_b15, filename=\"../data/bm25_ranking_b15.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "tfidf_df = pd.read_csv(\"../data/tf_idf_ranking.csv\").head(20)\n",
    "our_score_15_df = pd.read_csv(\"../data/our_score15_ranking.csv\").head(20)\n",
    "our_score_70_df = pd.read_csv(\"../data/our_score70_ranking.csv\").head(20)\n",
    "bm25_b7_df = pd.read_csv(\"../data/bm25_ranking_b7.csv\").head(20)\n",
    "bm25_b15_df = pd.read_csv(\"../data/bm25_ranking_b15.csv\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rank_comparison(dfs, score_cols, token_tweets):\n",
    "    \"\"\"\n",
    "    Plots accumulated position points for documents across selected scoring methods.\n",
    "\n",
    "    Parameters:\n",
    "    - dfs: Dictionary where keys are method names and values are dataframes with 'Document ID' and 'score' columns.\n",
    "    - score_cols: List of keys from dfs to specify which methods to compare.\n",
    "    \"\"\"\n",
    "    # Rename columns and assign ranking points\n",
    "    for name in dfs:\n",
    "        dfs[name].rename(columns={'Document ID': 'document_id', 'score': f'points_{name}'}, inplace=True)\n",
    "        dfs[name][f'points_{name}'] = range(20, 0, -1)  # Rank position points: 1 = 20, 2 = 19, ..., 20 = 1\n",
    "\n",
    "    # Merge dataframes based on selected methods\n",
    "    merged_df = dfs[score_cols[0]][['document_id', f'points_{score_cols[0]}']]\n",
    "    for col in score_cols[1:]:\n",
    "        merged_df = pd.merge(merged_df, dfs[col][['document_id', f'points_{col}']], on='document_id', how='outer')\n",
    "\n",
    "    # Fill NaN values with 0 for documents not present in all rankings\n",
    "    merged_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Calculate total points across selected methods\n",
    "    merged_df['total_points'] = merged_df[[f'points_{col}' for col in score_cols]].sum(axis=1)\n",
    "\n",
    "    # Sort documents by total points\n",
    "    merged_df.sort_values(by='total_points', ascending=False, inplace=True)\n",
    "\n",
    "    # Prepare data for stacked bar plot\n",
    "    documents = merged_df['document_id']\n",
    "    colors = ['skyblue', 'lightgreen', 'salmon', 'plum', 'orange']  # Predefined colors for up to 5 methods\n",
    "    color_map = {col: colors[i % len(colors)] for i, col in enumerate(score_cols)}\n",
    "\n",
    "    # Create a new list of formatted document labels with lengths\n",
    "    formatted_documents = [f\"{doc} ({len(token_tweets[doc])})\" for doc in documents]\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "    \n",
    "    # Accumulate points for each method in a stacked manner\n",
    "    left_values = [0] * len(documents)\n",
    "    for col in score_cols:\n",
    "        bars = ax.barh(formatted_documents, merged_df[f'points_{col}'], left=left_values, color=color_map[col], label=col)\n",
    "        \n",
    "        # Add point value annotations inside each bar\n",
    "        for bar, value in zip(bars, merged_df[f'points_{col}']):\n",
    "            if value > 0:  # Only annotate non-zero points\n",
    "                value = 21 - value\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_y() + bar.get_height() / 2,\n",
    "                    f'{int(value)}',\n",
    "                    ha='center', va='center', color='black', fontsize=8, weight='bold'\n",
    "                )\n",
    "                \n",
    "        left_values = left_values + merged_df[f'points_{col}']\n",
    "\n",
    "    # Add legend and labels\n",
    "    ax.set_xlabel('Total Points (Based on Ranking Position)')\n",
    "    ax.set_title('Accumulated Position Points by Document in Selected Top 20 Rankings')\n",
    "    ax.legend(loc='lower right')\n",
    "    \n",
    "    # Show plot\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the highest rank at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes in a dictionary with custom names\n",
    "dfs = {\n",
    "    'tfidf': tfidf_df,\n",
    "    'our_score_15': our_score_15_df,\n",
    "    'our_score_70': our_score_70_df,\n",
    "    'bm25_b7': bm25_b7_df,\n",
    "    'bm25_b15': bm25_b15_df\n",
    "\n",
    "}\n",
    "\n",
    "# Plot only tfidf and bm25\n",
    "plot_rank_comparison(dfs, ['tfidf','bm25_b7','bm25_b15','our_score_15', 'our_score_70'], token_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only tfidf and bm25\n",
    "plot_rank_comparison(dfs, ['tfidf','bm25_b7', 'bm25_b15'], token_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rank_comparison(dfs, ['tfidf', 'bm25_b7'], token_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rank_comparison(dfs, ['tfidf', 'bm25_b15'], token_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only tfidf and bm25\n",
    "plot_rank_comparison(dfs, ['our_score_15', 'our_score_70'], token_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Word2vec with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(token_tweets.values(), workers=4, vector_size=100, min_count=50, window=10, sample=1e-3)\n",
    "tweet2vec_dict = irk.create_tweet2vec(token_tweets, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"\\n\\n*RESULTS FOR\", str(\"query\" + str(i+1)), \"*\\n\")\n",
    "    scores = irk.tweet2vec_cossim(tweet2vec_dict, model, ipp.build_terms(queries[i]))\n",
    "    irk.display_scores_tf_idf(scores, docid_to_tweetid, tweets, n=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
