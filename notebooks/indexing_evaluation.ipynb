{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:78px\">Final Project IRWA (2024-2025)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:48px\">Part 2: Indexing and Evaluation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Local application imports\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in locals() else os.getcwd()\n",
    "project_root = os.path.join(current_dir, '..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import irwa.loading as ild \n",
    "import irwa.preprocessing as ipp\n",
    "import irwa.indexing as ind\n",
    "import irwa.ranking as irk\n",
    "\n",
    "# The following lines allow for autoreload of modules. They allow changes in modules without the need to reload the kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 117407 tweets\n",
      "Loaded 48429 documents with their corresponding tokenized tweet content\n"
     ]
    }
   ],
   "source": [
    "# Loading and preprocessing\n",
    "file_path = '../data/farmers-protest-tweets.json'\n",
    "tweets = ild.load_tweets_from_json(file_path)\n",
    "print(f\"Loaded {len(tweets)} tweets\")\n",
    "tweet_document_ids_map_df = \"../data/tweet_document_ids_map.csv\"\n",
    "docid_to_tweetid, token_tweets = ipp.create_tokenized_dictionary(tweets, tweet_document_ids_map_df)\n",
    "print(f\"Loaded {len(token_tweets)} documents with their corresponding tokenized tweet content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted Index construction\n",
    "inverted_index = ind.create_inverted_index(token_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of test queries\n",
    "query1 = \"Indian protest\"      # Example given in handout\n",
    "query2 = \"support farmers\"     # Example given in handout\n",
    "query3 = \"Delhi farmers\"\n",
    "query4 = \"Government corrupt\"\n",
    "query5 = \"president India\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Results:\n",
      "Document doc_13095: 13.034242103125635\n",
      "Content: INDIAN FARMERS are protesting in DELHI for last 3 months. 220+ farmers had died so far in #FarmersProtest .Protests are held all over the world to show solidarity with Indian Farmers.A protest will be held in Australia this Sunday.\n",
      "#DPstopIntimidatingFarmers\n",
      "@UNHumanRights\n",
      "@bbc https://t.co/Ct5hqEEXRE\n",
      "Document doc_445: 12.573739182581026\n",
      "Content: Farmers Protest | Pawri Ho Rahi Hai ðŸŒ¾\n",
      "Dedicated to The 2020â€“2021 Indian farmers' protest. #FarmersProtestâ€‹ is an ongoing protest against three farm acts which were passed by the Parliament of India in Sep 2020. Millions of farmers are protesting in India.\n",
      "https://t.co/cR5ltghf6X\n",
      "Document doc_5374: 11.53260069180757\n",
      "Content: @VP Dear madam,\n",
      "Not only Indian farmers need justice but every Indian need justice who love democracy\n",
      "please save Indian democracy and Indian constitutionðŸ™ðŸ™ðŸ™\n",
      "#FarmersProtest\n",
      "Document doc_9022: 11.53260069180757\n",
      "Content: #modi_rojgar_do - indian youth.\n",
      "#FarmersProtest- kaala kanoon hates- indian farmers.\n",
      "#Petrol100NotOut - loot kam karo - indian middle class.\n",
      "#guspaitkamkaro - indian soldiers\n",
      "\n",
      "Modi is busy desperately trying to win bengal, as if without he can't manage any of the above.\n",
      "Document doc_37090: 11.07209777126296\n",
      "Content: @balbir59 @varinder11 Nothing is dented. Those are farmers. Indian media didn't show Farmers putting Indian Flag at Red Fort as well.  Propaganda led by Indian government and media. India government also forced Twitter to ban accounts supporting Farmers Protest  #FarmersProtest https://t.co/6MSies6RC5\n"
     ]
    }
   ],
   "source": [
    "# Ranking results with TF-IDF\n",
    "scores_q1 = irk.tf_idf(inverted_index, query1, token_tweets)\n",
    "irk.sort_scores_tf_idf(scores_q1, docid_to_tweetid, tweets, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Results:\n",
      "Document doc_36673: 10.905015117394331\n",
      "Content: We Support #FarmersProtest\n",
      "We Support #GretaThunberg \n",
      "We Support #Rehanna\n",
      "We Support #NodeepKaur\n",
      "We Support #DishaRavi\n",
      "\n",
      "#ReleaseDishaRavi #ReleaseNovdeepKaur\n",
      "Document doc_3199: 10.718059609339209\n",
      "Content: @dhruv_rathee Not a farmer\n",
      "No fOd\n",
      "Not a farmer\n",
      "No greenery\n",
      "Not a farmer\n",
      "Not haPiness\n",
      "Not a farmer\n",
      "Not healthy\n",
      "Not a farmer\n",
      "No Humans and animals\n",
      "Not a farmer\n",
      "No employment,business,economy\n",
      "Not a farmer\n",
      "No progreS of the nation\n",
      "If not farmer\n",
      "Is the country not even the land\n",
      "#FarmersProtest\n",
      "Document doc_22998: 10.562281423938803\n",
      "Content: I support farmers. Supporting farmers is not a anti national deed.Every citizen must support farmers. Please back 3 farm reform bill.#FarmersProtest\n",
      "Document doc_33745: 10.562281423938803\n",
      "Content: Increasingly, supporting farmers is becoming a crime. From Journalists to Activists, doesn't matter who you are, if you Support Farmers you will be attacked by the Government. Supporting Farmers Is Not A Crime!\n",
      "#DishaRavi #FarmersProtest https://t.co/cBJpI9SozO\n",
      "Document doc_31432: 9.721035851627338\n",
      "Content: This is a farmers protest for farmers by farmers , common people !! Please keep supporting farmers if these people can still support after losing their son #FarmersProtest https://t.co/KYj5qVMAAy\n"
     ]
    }
   ],
   "source": [
    "# Ranking results with TF-IDF\n",
    "scores_q2 = irk.tf_idf(inverted_index, query2, token_tweets)\n",
    "irk.sort_scores_tf_idf(scores_q2, docid_to_tweetid, tweets, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Results:\n",
      "Document doc_21757: 13.022516656851371\n",
      "Content: The 'Delhi Chalo' farmers' protest at border points of New Delhi has entered theÂ 84th day today. Thousands of farmers, especially from Punjab and Haryana, are staging a sit-in protest along Delhi borders.\n",
      " #RailRokoForFarmers #FarmersProtest\n",
      "Document doc_941: 11.68275920568397\n",
      "Content: @anilca95 @ArvindKejriwal Our honorable CM is busy with farmers from outside and handed over DELHI to #FarmersProtest He has no time or attention to problems of Delhi, yamuna continues to suffer, pollute and no govt has any policy or plan to #save yamuna! Sic of you Delhi political circles\n",
      "Document doc_29928: 11.68275920568397\n",
      "Content: Today, the 82nd day of the 'Delhi Chalo' demonstrations at New Delhi boundary areas. A sit-in protest along the Delhi border is being staged by thousands of farmers, \n",
      "\n",
      "#FarmersProtest  #DelhiChalo  #ProtestTopStories\n",
      "\n",
      "https://t.co/O67STnJJ0M\n",
      "Document doc_42270: 11.68275920568397\n",
      "Content: #FarmersProtest     @FarmersOfTheUK I read late last night that despite Delhi High Court orders , Delhi Police did not release the protesting farmers, Come on Delhi Police the world is watching you , please stand on the right side of morality and historyðŸ https://t.co/WEPU6mi97L\n",
      "Document doc_6415: 10.914606856513249\n",
      "Content: Camped on the highways of Delhi for 3 months- farmers at Tikri Border bring beauty of nature to the industrial edges of Delhi. Farmers doing what farmers do best ðŸ˜âœŠðŸšœ #FarmersProtest @cnni @PBS @NBCNews @abcnews @BBCWorld @guardian @AJEnglish @SusanSarandon @HuffPost https://t.co/yNjqQcjRNF\n"
     ]
    }
   ],
   "source": [
    "# Ranking results with TF-IDF\n",
    "scores_q3 = irk.tf_idf(inverted_index, query3, token_tweets)\n",
    "irk.sort_scores_tf_idf(scores_q3, docid_to_tweetid, tweets, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Results:\n",
      "Document doc_4328: 14.847119073774913\n",
      "Content: Nothing different between British government and Modi Government. I think British government was more sensitive than this Modi Government because they repealed the laws but this government is too much ignorant.\n",
      "#FarmersProtest\n",
      "#DPstopIntimidatingFarmers\n",
      "#Pagdi_Sambhal_Jatta\n",
      "Document doc_37665: 14.45743958052082\n",
      "Content: Good news for Indian, bad news for Fake #FarmersProtest corrupt #DhruvRathee corrupt #BarkhaDutt corrupt @ndtv Antinational #Sikh #Khalistanis https://t.co/FUeSUyjII8\n",
      "Document doc_14671: 12.60771686843553\n",
      "Content: #MSP_à¤•à¤¿à¤¸à¤¾à¤¨_à¤•à¤¾_à¤¹à¤• \n",
      "Corruption Corruption thats what this Government will be Remembered for #DPstopIntimidatingFarmers\n",
      "#FarmersProtest https://t.co/aTNdwitLS9\n",
      "Document doc_14680: 12.60771686843553\n",
      "Content: Corruption Corruption thats what this Government will be Remembered for #DPstopIntimidatingFarmers\n",
      "#FarmersProtest https://t.co/Oxe9SDB01w\n",
      "#DPstopIntimidatingFarmers\n",
      "Document doc_14701: 12.60771686843553\n",
      "Content: Corruption Corruption thats what this Government will be Remembered for #DPstopIntimidatingFarmers\n",
      "#FarmersProtest https://t.co/7QsxGwbWmr\n"
     ]
    }
   ],
   "source": [
    "# Ranking results with TF-IDF\n",
    "scores_q4 = irk.tf_idf(inverted_index, query4, token_tweets)\n",
    "irk.sort_scores_tf_idf(scores_q4,docid_to_tweetid, tweets, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Results:\n",
      "Document doc_30908: 14.602910470127531\n",
      "Content: US Lawyers write to President #Biden on #Farmers' Protests:\n",
      "'Your administration comes to office at a time when minority communities across India are in peril,' notes the letter, urging the US President to act.\n",
      "#FarmersProtest https://t.co/wlQVau3nkw\n",
      "Document doc_30305: 13.059745520898112\n",
      "Content: India doesn't give a shit about minorities. India doesn't give a shit about minorities. India doesn't give a shit about minorities. India doesn't give a shit about minorities. India doesn't give a shit about minorities. India doesn't give a shit about minorities. #FarmersProtest\n",
      "Document doc_15774: 12.426286216644513\n",
      "Content: @mausamii2u @sardesairajdeep @iwpcdelhi @AishPaliwal @kamaljitsandhu Iss tuchha jeevi.. very own ? Amazing ðŸ‘\n",
      "\n",
      "He is \"Liar-In-Chief\". Has been taken 2 task by many including Ex President Pranab da, current President Kovind. Got suspended frm his own employer for his blatant lies during #FarmersProtest Shame\n",
      "\n",
      "@BesuraTaansane \n",
      "@Aniiiiish @IndiaToday\n",
      "Document doc_44484: 12.426286216644513\n",
      "Content: @meenaharris Thank you for your support @meenaharris ðŸ™\n",
      "Will the Hon'ble US President and Hon'ble US Vice President talk about the Indian Farmer's issues? \n",
      "#FarmersProtest\n",
      "Document doc_26023: 10.883121267415092\n",
      "Content: mandeeptoronto: #FarmersMakeIndia\n",
      "\n",
      "Farmers are the Backbone of India\n",
      "Farmers are the Blood of India\n",
      "Farmers make the Food of India\n",
      "Farmers are the People of India\n",
      "Farmers are India\n",
      "\n",
      "#FarmersProtest https://t.co/Wx7GsuMPYr https://t.co/EnHIwtiLml\n"
     ]
    }
   ],
   "source": [
    "# Ranking results with TF-IDF\n",
    "scores_q5 = irk.tf_idf(inverted_index, query5, token_tweets)\n",
    "irk.sort_scores_tf_idf(scores_q5, docid_to_tweetid, tweets, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_to_ev_1 = \"People's rights\"\n",
    "query_to_ev_2 = \"Indian Government\"\n",
    "\n",
    "queryid2text = {\n",
    "    1: query_to_ev_1,\n",
    "    2: query_to_ev_2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_evq1 = irk.tf_idf(inverted_index, query_to_ev_1, token_tweets)\n",
    "scores_evq2 = irk.tf_idf(inverted_index, query_to_ev_2, token_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionaries to DataFrames\n",
    "df_query_1 = pd.DataFrame(list(scores_evq1.items()), columns=['doc_id', 'doc_score'])\n",
    "df_query_2 = pd.DataFrame(list(scores_evq2.items()), columns=['doc_id', 'doc_score'])\n",
    "\n",
    "# Add a column for query_id\n",
    "df_query_1['query_id'] = 1\n",
    "df_query_2['query_id'] = 2\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "search_results = pd.concat([df_query_1, df_query_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.read_csv(\"../data/evaluation_gt.csv\", delimiter=\";\")\n",
    "results = pd.merge(evaluation, search_results, how='left', left_on=['docId', 'query_id'], right_on=['doc_id', 'query_id'])\n",
    "results.drop(columns=['doc_id'], inplace=True)\n",
    "# Fill Nan with 0 as it means that is has not found any relevant score for such query\n",
    "results.fillna(0, inplace=True)\n",
    "\n",
    "#Rename columns for better usage\n",
    "results.columns = [\"doc_id\", \"query_id\", \"is_relevant\", \"predicted_relevance\" ]\n",
    "mean_predicted_relevance = results['predicted_relevance'].mean()\n",
    "std_predicted_relevance = results['predicted_relevance'].std()\n",
    "\n",
    "# Standardizing the predicted_relevance column\n",
    "results['predicted_relevance'] = (results['predicted_relevance'] - mean_predicted_relevance) / std_predicted_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-------------------------------------------------------------------------------------------\n",
      "Out of 30 documents, 15 are found relevant for query 'people's rights'\n",
      "-------------------------------------------------------------------------------------------\n",
      "2\n",
      "-------------------------------------------------------------------------------------------\n",
      "Out of 30 documents, 15 are found relevant for query 'Indian Government'\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for query in results['query_id'].unique():\n",
    "    print(query)\n",
    "    # Count relevant documents for the current query\n",
    "    relevant_count = results[results['query_id'] == query]['is_relevant'].sum()\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------------------------------\")\n",
    "    print(f\"Out of {len(results[results['query_id'] == query])} documents, {relevant_count} are found relevant for query '{queryid2text.get(query, 'Unknown query')}'\")\n",
    "    print(\"-------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@K (P@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(doc_score, y_score, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "    recall @k : float\n",
    "\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    doc_score = doc_score[order[:k]]\n",
    "    relevant = sum(doc_score == 1)\n",
    "    precision = float(relevant) / k\n",
    "\n",
    "    total_relevant = sum(doc_score)\n",
    "    if total_relevant == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = float(relevant) / total_relevant\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuari\\AppData\\Local\\Temp\\ipykernel_5496\\2359606978.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  current_query_res = results[search_results[\"query_id\"] == 1]\n"
     ]
    }
   ],
   "source": [
    "# Assign the current query\n",
    "current_query_res = results[search_results[\"query_id\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Precision@25: 0.92\n",
      "\n",
      "==> Precision@20: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_k25, rec_k25 = precision_at_k(current_query_res[\"is_relevant\"], current_query_res[\"predicted_relevance\"], 25)\n",
    "pre_k20, rec_k20 = precision_at_k(current_query_res[\"is_relevant\"], current_query_res[\"predicted_relevance\"], 20)\n",
    "\n",
    "\n",
    "print(\"==> Precision@{}: {}\\n\".format(25, pre_k25))\n",
    "print(\"==> Precision@{}: {}\\n\".format(20, pre_k20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall@K (R@k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Recall@25: 1.0\n",
      "\n",
      "==> Recall@20: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"==> Recall@{}: {}\\n\".format(25, rec_k25))\n",
    "print(\"==> Recall@{}: {}\\n\".format(20, rec_k20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avgerage Precision@K (P@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision_at_k(doc_score, y_score, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    average precision @k : floa\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]  # get the list of indexes of the predicted score sorted in descending order.\n",
    "\n",
    "    prec_at_i = 0\n",
    "    prec_at_i_list = []\n",
    "    number_of_relevant = 0\n",
    "    number_to_iterate = min(k, len(order))\n",
    "\n",
    "    for i in range(number_to_iterate):\n",
    "        if doc_score[order[i]] == 1:\n",
    "            number_of_relevant += 1\n",
    "            prec_at_i = number_of_relevant / (i + 1)\n",
    "            prec_at_i_list.append(prec_at_i)\n",
    "\n",
    "    if number_of_relevant == 0:\n",
    "        return 0\n",
    "    else:\n",
    "      return np.sum(prec_at_i_list) / number_of_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9870474390134127)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_precision_at_k(np.array(current_query_res[\"is_relevant\"]), np.array(current_query_res[\"predicted_relevance\"]), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9860869565217392)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "k = 25\n",
    "temp = current_query_res.sort_values(\"predicted_relevance\", ascending=False).head(k)\n",
    "average_precision_score(np.array(temp[\"is_relevant\"]), np.array(temp[\"predicted_relevance\"][:k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(precision, recall):\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 Score for k = 20 is: 0.9743589743589743\n",
      "F-1 Score for k = 25 is: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f\"F-1 Score for k = 20 is: {f1_score(pre_k20, rec_k20)}\")\n",
    "print(f\"F-1 Score for k = 25 is: {f1_score(pre_k25, rec_k25)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(search_res, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_res: search results dataset containing:\n",
    "        query_id: query id.\n",
    "        doc_id: document id.\n",
    "        predicted_relevance: relevance predicted through LightGBM.\n",
    "        doc_score: actual score of the document for the query (ground truth).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mean average precision @ k : float\n",
    "    \"\"\"\n",
    "    avp = []\n",
    "    for q in search_res[\"query_id\"].unique():  # loop over all query id\n",
    "        curr_data = search_res[search_res[\"query_id\"] == q]  # select data for current query\n",
    "        avp.append(avg_precision_at_k(np.array(curr_data[\"is_relevant\"]),\n",
    "                   np.array(curr_data[\"predicted_relevance\"]), k))  #append average precision for current query\n",
    "    return np.sum(avp) / len(avp), avp  # return mean average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9625440630797774)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_k, avp = map_at_k(results, 25)\n",
    "map_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Reciprocal Rank (MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr_at_k(doc_score, y_score, k=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Reciprocal Rank for qurrent query\n",
    "    \"\"\"\n",
    "\n",
    "    order = np.argsort(y_score)[::-1]  # get the list of indexes of the predicted score sorted in descending order.\n",
    "    doc_score = np.take(doc_score, order[:k])  # sort the actual relevance label of the documents based on predicted score(hint: np.take) and take first k.\n",
    "    if np.sum(doc_score) == 0:  # if there are not relevant doument return 0\n",
    "        return 0\n",
    "    return 1 / (np.argmax(doc_score == 1) + 1)  # hint: to get the position of the first relevant document use \"np.argmax\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "labels = np.array(results[results['query_id'] == 1][\"is_relevant\"])\n",
    "scores = np.array(results[results['query_id'] == 1][\"predicted_relevance\"])\n",
    "np.round(rr_at_k(labels, scores, 13), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain (NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(doc_score, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]  # get the list of indexes of the predicted score sorted in descending order.\n",
    "    doc_score = np.take(doc_score, order[:k])  # sort the actual relevance label of the documents based on predicted score(hint: np.take) and take first k.\n",
    "    gain = 2 ** doc_score - 1  # Compute gain (use formula 7 above)\n",
    "    discounts = np.log2(np.arange(len(doc_score)) + 2)  # Compute denominator\n",
    "    return np.sum(gain / discounts)  #return dcg@k\n",
    "\n",
    "\n",
    "def ndcg_at_k(doc_score, y_score, k=10):\n",
    "    dcg_max = dcg_at_k(doc_score, doc_score, k)\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return np.round(dcg_at_k(doc_score, y_score, k) / dcg_max, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg@5 for query with query_id=1: 1.0\n"
     ]
    }
   ],
   "source": [
    "ndcg_k = np.round(ndcg_at_k(labels, scores, k), 4)\n",
    "print(\"ndcg@{} for query with query_id={}: {}\".format(k, 1, ndcg_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg@5 for query with query_id=2: 1.0\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(results[results['query_id'] == 2][\"is_relevant\"])\n",
    "scores = np.array(results[results['query_id'] == 2][\"predicted_relevance\"])\n",
    "ndcg_k = np.round(ndcg_at_k(labels, scores, k), 4)\n",
    "print(\"ndcg@{} for query with query_id={}: {}\".format(k, 2, ndcg_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@K (P@K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall@K (R@K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Precision@K (P@K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score@K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Reciprocal Rank (MRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain (NDCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
